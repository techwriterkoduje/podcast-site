{"pageProps":{"episodeData":{"title":"#21 Tech Writer zbiera informacje ze stron, czyli jak można wykorzystać web scraping","description":"<p>Web scraping to zbieranie danych ze stron internetowych. Google, na przykład, robi to, żeby indeksować cały internet w swojej wyszukiwarce. Web scraping wykorzystuje się też do monitorowania cen w konkurencyjnych sklepach internetowych.</p>\n<p>U nas w firmie używamy web scrapingu, żeby indeksować dokumentację dla naszej wyszukiwarki. To samo rozwiązanie wykorzystujemy też, żeby sprawdzać czy wszystkie linki działają. Wyniki web scrapingu zapisujemy &nbsp;w Elasticsearchu, a potem analizujemy je za pomocą raportów i filtrów &nbsp;w Kibanie. Dzięki temu stworzyliśmy zalążek panelu kontrolnego, na którym widać aktualną jakość naszej dokumentacji.</p>\n<p>W niedalekiej przyszłości chcemy &nbsp;rozszerzyć nasze rozwiązanie o dodatkowe funkcje. Planujemy, na przykład, testować strony pod kątem wymaganych elementów i zgodności z regułami &nbsp;naszego style guide’a. Kolejną opcją jest sprawdzanie czy w treści nie ma błędów gramatycznych i stylistycznych oraz czy język, którego używamy do tworzenia instrukcji jest wystarczająco przejrzysty.</p>\n<p>Co można jeszcze zrobić za pomocą web scrapingu? Jakie inne testy są potrzebne w świecie dokumentacji technicznej i pisania ustrukturyzowanego? Zapraszamy do słuchania.</p>\n<p><strong>Informacje dodatkowe:</strong></p>\n<p>Web scraping: <a href=\"//\"><a href=\"https://en.wikipedia.org/wiki/Web_scraping\" target=\"_blank\">https://en.wikipedia.org/wiki/Web_scraping</a></a></p>\n<p>Scrapy: <a href=\"//\"><a href=\"https://scrapy.org/\" target=\"_blank\">https://scrapy.org/</a></a></p>\n<p>Elastic (Elasticsearch, Kibana): <a href=\"//\"><a href=\"https://www.elastic.co/\" target=\"_blank\">https://www.elastic.co/</a></a></p>\n<p>curl: <a href=\"//\"><a href=\"https://curl.haxx.se/\" target=\"_blank\">https://curl.haxx.se/</a></a></p>\n<p>Textstat: <a href=\"//\"><a href=\"https://github.com/shivam5992/textstat\" target=\"_blank\">https://github.com/shivam5992/textstat</a></a></p>\n<p>spaCy: <a href=\"//\"><a href=\"https://spacy.io/\" target=\"_blank\">https://spacy.io/</a></a></p>\n<p>Selenium: <a href=\"//\"><a href=\"https://www.selenium.dev/\" target=\"_blank\">https://www.selenium.dev/</a></a></p>\n<p>TestCafe: <a href=\"//\"><a href=\"https://devexpress.github.io/testcafe/\" target=\"_blank\">https://devexpress.github.io/testcafe/</a></a></p>\n<p>Vale: <a href=\"//\"><a href=\"https://github.com/errata-ai/vale\" target=\"_blank\">https://github.com/errata-ai/vale</a></a></p>\n","blurb":"Web scraping to zbieranie danych ze stron internetowych. Google, na przykład, robi to, żeby indeksować cały internet w swojej wyszukiwarce. Web scraping wykorzy","pubDate":"Tue, 15 Sep 2020 06:54:41 GMT","anchorLink":"https://anchor.fm/docdeveloper/episodes/21-Tech-Writer-zbiera-informacje-ze-stron--czyli-jak-mona-wykorzysta-web-scraping-ejj0ah","audioUrl":"https://anchor.fm/s/8afba9c/podcast/play/19545873/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2020-8-14%2Fed0aad87-1c9c-f554-da79-8239ef20726b.mp3","episodeNumber":21,"episodeLink":"/blog/2020/9/15/21","duration":"00:32:54"}},"__N_SSG":true}